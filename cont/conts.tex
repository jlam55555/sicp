\documentclass[]{article}

\usepackage{minted}
\usepackage{hyperref}

\begin{document}
\title{Variation on a Scheme:\\Multiple implicit first-class continuations\\
  \vspace{6pt}
  \large{} and a general survey of continuations}
\author{Jonathan Lam}
\date{\today{}}

\maketitle{}

\section{Introduction}
\label{sec:intr}

This is for the completion of ECE491: Structure and Implementation of Computer Programs, based on the text of the same name by Abelson and Sussman. The assignment was to implement a variation on the interpreter presented in sections 4.1-4.4.

This work extends the work presented in section 4.3: ``Variations on a Scheme -- Nondeterministic Computing.'' The section uses implicit continuations to implement the \mintinline{scheme}|amb| keyword. This work extends that in two ways by:
\begin{itemize}
\item providing an arbitrary number of continuations, rather than only two (success and fail); and
\item exposing continuations as first-class objects using the \mintinline{scheme}|call/cc| interface
\end{itemize}

Additionally, a significant portion of this project was dedicated to exploring the theory and use cases of continuations, so there will be some backgrounds and examples of common use cases.

\section{Background}
\label{sec:back}

This sections goes far beyond the scope of the implementation. However, I have yet to find a resource that shows the breadth of the many facets of continuations, so I will attempt to highlight why continuations are so general here. Many of the interesting examples and intuition come from Matt Might's excellent blog posts about continuations, coroutines, and CSP. TODO: cite these

\subsection{What are continuations?}
\label{sec:what}

TODO

\subsubsection{Continuation-passing style (CPS)}
\label{sec:cps}

Continuation-passing style is a very instructive tool for discussing continuations at a functional level.

First-class continuations can be implemented in any language with lambdas (functions with lexical closures), by performing a syntactical transfomation of functions to CPS, which is shown in Figure \ref{fig:cps}. Looking at the CPS form, we can characterize a continuation in the following ways:
\begin{itemize}
\item Each function takes its continuation as an extra parameter.
\item A continuation is only invoked as a tail-call (if a continuation is called, its \href{https://wiki.c2.com/?CallWithCurrentContinuation}{``then-current continuation will be abandoned''}, so a non-tail call would be wasteful).
\item A continuation takes the result of the previous instruction as its singular parameter.
\end{itemize}

Note that continuations in CPS are ordinary functions (``callbacks'' in event-driven coding), and thus can be used to implement continuations in a language that doesn't support implicit continuations. CPS is used by Abelson and Sussman to implement continuations in their nondeterministic interpreter, and this is extended for this project.

Other ways to implement continuations will be discussed in \S{\ref{sec:thre}}.

\begin{figure}[h]
  \centering
\begin{minted}{scheme}
;;; without continuations; uses regular return
(define (add a b)
  (+ a b))
(define (mult a b)
  (* a b))
(define (a*b+c a b)
  (add (mult a b) c))

(display (a*b+c 1 2 3)) ;; => 5

;;; continuations using CPS
(define (add a b cont)
  (cont (+ a b)))
(define (mult a b cont)
  (cont (* a b)))
(define (a*b+c a b c cont)
  (mult a b (lambda (a*b)
              (add a*b c cont))))

(a*b+c 1 2 3 display) ;; => 5
\end{minted}
  \caption{Continuation passing style example}
  \label{fig:cps}
\end{figure}

\subsection{Nondeterministic computing and the \mintinline{scheme}|amb| keyword}
\label{sec:nond}

Abelson and Sussman implement the \mintinline{scheme}|amb| keyword in Scheme. This keyword takes a set of possible values as input, and produces a value\footnote{It is ``nondeterministic'' because the keyword only has to return \textit{a} value that satisfies the assertions (conditions). The exact choice of value is not important. Thus it may be better viewed as a SAT-solver, as Matt Might implements using CPS in his \href{https://matt.might.net/articles/programming-with-continuations--exceptions-backtracking-search-threads-generators-coroutines/}{blog post on continuations}.} that satisfies all of the assertions placed on the value in the future. For example, the example shown in Figure \ref{fig:amb} may assign to \mintinline{scheme}|a| either \texttt{3} or \texttt{5}.

\begin{figure}[h]
  \centering
\begin{minted}{scheme}
(define a (amb '(1 2 3 4 5)))
(require a odd?)
(require a prime?)
\end{minted}
  \caption{Sample usage of \mintinline{scheme}|amb|}
  \label{fig:amb}
\end{figure}

This can be implemented using a search over all the possible solutions. What is really impressive is that we are able to state SAT problem in a declarative manner, rather than embedding it in an algorithm\footnote{The same is true for generators, and is what makes them so powerful.}. Even more impressively, we are able to state the constraints on an ambiguous value in its \textit{future}, and possibly after the value has already been used.

The key part to this implementation is the implicit\footnote{This is my own terminology. I use ``implicit'' to refer to (reified) continuations that are baked into the language and can be used by the interpreter to perform control flow. Optionally, the interpreter may choose to expose these continuations via interfaces such as \mintinline{scheme}|call/cc|. I use ``explicit'' to refer to CPS, in which reified continuations are implemented by the user as explicit procedure calls.} use of continuations. In this case, an additional error continuation is provided to handle the case of a condition failing -- this causes the next value to be tried (if any). This also necessarily undoes any side effects (such as variable mutation) to effective ``time travel'' to the point in the program where the ambiguous value is declared.

Functionally, this can be thought of as a try/catch statement, without the user having to explicitly code the control flow (and simply because there is not a builtin try/catch statement in Scheme).

The interpreter from section 4.3 is based off of the version in 4.1, which uses a procedure-based intermediate representation (IR) for all expressions. The expression is first parsed using the Scheme \mintinline{scheme}|read| procedure, and then semi-compiled into this IR to avoid parsing every time the expression is encountered (if the expression is invoked multiple times).

The form of the procedure representing the compiled expression (the expression IR) is shown in Figure \ref{fig:ir41}. Whenever the expression is invoked, this lambda is called with the current runtime environment.

The analogous expression IR for the nondeterministic backtracking interpreter from section 4.3 is shown in Figure \ref{fig:ir43}. At runtime, each expression is also given two continuations as parameters -- this is known as continuation-passing style (CPS). These continuations are ordinary procedures that should be used to pass around the results of computations. The success continuation takes the value from the previous computation and the failure continuation. The failure computation is special, its only purpose being to discard the value and reverse the stack and side effects so that the next value can be tried -- it does not need the value from the previous computation nor the success continuation.

\begin{figure}[h]
  \centering
\begin{minted}{scheme}
(lambda (env)
  ;; env stores the symbol table for the current scope
  ...)
\end{minted}
  \caption{Expression IR from section 4.1}
  \label{fig:ir41}
\end{figure}

\begin{figure}[h]
  \centering
\begin{minted}{scheme}
(lambda (env succeed-cont fail-cont)
  ;; succeed-cont is of the form (lambda (value fail-cont) ...)
  ;; fail-cont is of the form (lambda () ...)
  ...)
\end{minted}
  \caption{Expression IR from section 4.3}
  \label{fig:ir43}
\end{figure}

\subsection{Continuations versus other control-flow constructs}
\label{sec:cntf}

This section is structured similarly to the \href{https://en.wikipedia.org/wiki/Coroutine}{Wikipedia page on coroutines}, which is an excellent resource on coroutines.

\subsubsection{Continuations vs. gotos}
\label{sec:goto}

Gotos are the software equivalent to a jump instruction. They are very simple and limited. For example, they can only jump to other locations in the current function; jumping to another function without modifying the stack would cause relative-addressing (local variables) to break. Also unlike gotos, continuations usually return a value.

Continuations are more similar to C's \mintinline{c}|setjmp| and \mintinline{c}|longjmp| functions, which essentially save and restore a history of the stack. Not only does this allow you to jump to different functions, it also allows you to jump back multiple levels of the stack. However, reified continuations are more powerful (and expensive) in that they are both optionally-resumable and multiply-resumable\footnote{In order to be multiply-resumable, a continuation essentially needs to create a copy of the stack whenever it is executed. See the section on implementation}.

In \href{https://matt.might.net/articles/programming-with-continuations--exceptions-backtracking-search-threads-generators-coroutines/}{his blog post about continuations}, Matt Might suggests an idiom that behaves very similarly to \mintinline{c}|setjmp|/\mintinline{c}|longjmp|. For those who are unfamiliar with these functions, \mintinline{c}|setjmp| is similar to \mintinline{c}|fork| in that returns different values depending on the context. \mintinline{c}|setjmp| is encountered either it is the next statement to execute, or when \mintinline{c}|longjmp| jumps to it. In the first case, it will return a falsy value, and in the latter it will return the value specified in the \mintinline{c}|longjmp| call.

Might does not explicitly mention \mintinline{c}|setjmp|/\mintinline{c}|longjmp| in his blog post, but the interface is remarkably similar. See a simple error-handling program with a nonlocal jump in C/C++ is shown in Figure \ref{fig:setj}. The equivalent program in Scheme, using the \mintinline{scheme}|setjmp| idiom (Might calls this \mintinline{scheme}|current-continuation| in his examples), is shown in Figure \ref{fig:idio}.

Note that both \mintinline{c}|goto| and \mintinline{c}|setjmp| may be dangerous if there are side effects in the jumped code. \mintinline{c}|goto| is very dangerous since it can actually branch forward in a function, skipping variable initializations completely. \mintinline{c}|setjmp| is less dangerous in that it can only go back to a previous location on the stack (which should be safe), but may cause issues with dangling or incorrect pointers if cleanup code is skipped. Continuations (in Scheme) are safer because they cannot branch forward in time, and because garbage collection would manage dangling references.

\begin{figure}[h]
  \centering
\begin{minted}[]{c}
main() {
  jmp_buf env;
  int val;

  val = setjmp (env);
  if (val) {
    fprintf (stderr,"Error %d happened",val);
    exit (val);
  }

  /* code here */

  longjmp (env,101);   /* signaling an error */
}
\end{minted}
  \caption{Sample usage of \mintinline{c}|setjmp|/\mintinline{c}|longjmp|. Source: \href{http://www.cplusplus.com/reference/csetjmp/setjmp/}{cplusplus.com: \mintinline{c}|setjmp|}}
  \label{fig:setj}
\end{figure}

\begin{figure}[h]
  \centering
\begin{minted}{scheme}
(define (setjmp)
  (call/cc (lambda (cc) (cc cc))))

(let ([longjmp (setjmp)])
  (if [procedure? longjmp]
      ;; val == false
      (begin
        ;; code here
        (longjmp 101))
      ;; val = longjmp; val != false
      (error 'setjmp-example
             "Received error signal from longjmp"
             longjmp)))
\end{minted}
  \caption{Useful Scheme idiom using continuation that behaves like setjmp. Source: \href{https://matt.might.net/articles/programming-with-continuations--exceptions-backtracking-search-threads-generators-coroutines/}{Continuations by example: Exceptions, time-traveling search, generators, threads, and coroutines}}
  \label{fig:idio}
\end{figure}

\subsubsection{Continuations vs. return}
\label{sec:retu}

A continuation is like a return statement in that it usually passes a value and it (conceptually) unwinds the stack to a given location. However, continuations are optionally-resumable, multiply-resumable, and may unwind the stack more than one stack frame\footnote{The latter is useful in exception handling, or when needing to jump back many stack frames without the overhead of returning from each stack frame, such as in the backtracking nondeterministic interpreter.}.

\subsubsection{Continuations vs. callbacks}
\label{sec:call}

In CPS, continuations \textit{are} simply callbacks that follow a specific form. In general, first-class continuations feel very much like ordinary callbacks, in that they are invoked with the result of a computation. For example, in Javascript where event-driven coding is common, callbacks to asynchronous functions and the \mintinline{javascript}|Promise| API look very similar to CPS.

Of course, in the case of implicit continuations, there may be special machinery that manages program execution state that cannot be performed with a regular procedure call, but the API is the same as a procedure.

Note that callbacks are also multiply-resumable, optionally-resumable, and capture program state (capture its lexical environment). In general, we can think of continuations as a specific type of callback.

\subsubsection{Continuations vs. monads}
\label{sec:mona}

Haskell users may know that continuations exist as a monad (\href{https://hackage.haskell.org/package/mtl-2.2.2/docs/Control-Monad-Cont.html}{\mintinline{haskell}|Control.Monad.Cont|}). Even for those who don't (but are familiar with monads), the continuation's structure should feel monadic:
\begin{itemize}
\item Continuations act like a wrapper around a computation.
\item Chaining computations looks very similar to the bind operation.n
\item Continuations are a control-flow structure.
\end{itemize}

Consider Figure \ref{fig:hask}, the Haskell analog of the CPS example shown in Figure \ref{fig:cps}. Note that Haskell also has the \mintinline{haskell}|callCC| interface, similar to the \mintinline{scheme}|call/cc| procedure. Figure \ref{fig:mona} shows a sample monad instance declaration for the continuation type. Unsurprisingly, the syntax between Scheme and Haskell turns out to be very similar, even when Scheme continuations feel like procedures and Haskell continuations feel like monads.

\begin{figure}[h]
  \centering
\begin{minted}{haskell}
import           Control.Monad.Cont

mult             :: Int -> Int -> Cont r Int
mult a b         = return (a * b)

add              :: Int -> Int -> Cont r Int
add a b          = return (a + b)

-- a * b + c
atbpc            :: Int -> Int -> Int -> Cont r Int
atbpc a b c      = mult a b >>= add c

main = do runCont (atbpc 1 2 3) print
\end{minted}
  \caption{A sample Haskell continuation}
  \label{fig:hask}
\end{figure}

\begin{figure}[h]
  \centering
\begin{minted}{haskell}
newtype Cont r t = Cont ((t -> r) -> r)
  -- a value of type Cont r t is of the form Cont f,
  -- where f is a function of type (t -> r) -> r

runCont (Cont f) q = f q

instance Monad Cont where
  return :: t -> Cont r t
    -- return takes a value of type t
    -- and produces a Cont computation of type t with response type r.
  return x = Cont (\q -> q x)
    -- produce a Cont computation which given a question q,
    -- applies the question to the value x.

  (>>=) :: Cont r t -> (t -> Cont r s) -> Cont r s
  x >>= f = Cont (\q -> runCont x (\v -> runCont (f v) q))
\end{minted}
  \caption{A simplified continuation monad in Haskell. Source: \href{https://wiki.haskell.org/Cont_computations_as_question-answering_boxes}{Cont computations as question-answering boxes}}
  \label{fig:mona}
\end{figure}

\subsubsection{Continuations vs. threads}
\label{sec:vsth}

Continuations are like dormant, multiply-resumable threads. In particular, threads represent the current execution context of a program, and can be thought of as a snapshot of location on the stack. However, you cannot resume a thread from the same position  multiple times, unlike continuations.

\href{https://wiki.c2.com/?ContinuationExplanation}{C2 Wiki's ContinuationExplanation} hints that threads can be used to implement continuations, and vice versa. It also mentions that some thread implementations, such as POSIX pthreads, are not as powerful as continuations and cannot fully implement all continuation use cases. Continuation implementation will be further discussed in \S{\ref{sec:thre}}.

Continuations and execution context (and in particular, concurrent threads of execution) is part of the recurring theme, and will appear again in the discussion of coroutines.

\subsection{Uses for continuations}
\label{sec:uses}

\subsubsection{Callbacks and promises}
\label{sec:cacb}

Even in languages without implicit continuations, callbacks (that look and act a lot like continuations) are widely known and applied. Might's blog post \href{https://matt.might.net/articles/by-example-continuation-passing-style/}{By example: Continuation-passing style} provides the example of a CPS-style wrapper around the legacy \mintinline{javascript}|XMLHttpRequest| Ajax API\footnote{I'm not sure when this blog post was written, since the modern \mintinline{javascript}|fetch| API uses promises rather than callbacks.} that may look extremely natural for Javascript users, even without knowing about continuations.

Another asynchronous programming model in Javascript is the \mintinline{javascript}|Promise| API, which can be thought of as a modern wrapper around callbacks with some nice features. Promises are objects that contain a computation, and allow you to specify a success and error continuation explicitly using the \mintinline{javascript}|Promise::then()| and \mintinline{javascript}|Promise::catch()| methods. Javascript promises have a number of interesting features that make them more appealing than ordinary callbacks, such as their ability to be \mintinline{javascript}|await|-ed to avoid ``callback hell,'' the ability to automatically chain continuations, and the ability to attach multiple continuations to the same operation (which would be called asynchronously due to Javascript's event loop).

Since promises and callbacks are more or less functionally equivalent, scenarios that are expressible using callbacks are also expressible using promises. If we turn the example from Figure \ref{fig:cps} into CPS, and then transform that to use the \mintinline{javascript}|Promise| API, then we would get Figure \ref{fig:prom}.

\begin{figure}[h]
  \centering
\begin{minted}{javascript}
add = (a, b) =>
  new Promise((succeed_cont, fail_cont) => succeed_cont(a+b));

mult = (a, b) =>
  new Promise((succeed_cont, fail_cont) => succeed_cont(a*b));

atbpc = (a, b, c) =>
  new Promise((succeed_cont, fail_cont) =>
    mult(a, b).then(apb =>
      add(apb, c).then(succeed_cont)));

atbpc(1, 2, 3).then(console.log);
\end{minted}
  \caption{Continuations as Javascript \mintinline{javascript}|Promise|s}
  \label{fig:prom}
\end{figure}

As stated earlier, continuations model only a specific subset of callbacks or promises that are useful for execution; namely a single success callback that takes a single parameter (the result of the previous operation), and (optionally) an error callback that takes a single parameter (the error message). For my project, I aim to generalize implicit continuations to the case where there are an arbitrary number of continuations, which is similar to how a function is not limited in the number of callbacks it receives.

\subsubsection{Nonlocal branching}
\label{sec:nonl}

An example of nonlocal branching is the nondeterministic interpreter in \textit{SICP} section 4.3. Whenever there is a requirement conflict, we have to unwind the stack to the location of the relevant \mintinline{scheme}|amb| invocation, which may be nonlocal.

A personal example I have is when I had to write an A*-search algorithm and chose Scheme. Iterative deepening with a time limit was used; when the time limit was reached, rather than unwinding up the arbitrarily-deep search stack, a continuation served as a much simpler nonlocal goto. (Continuations were not used for the DFS.)

\subsubsection{Exception handling}
\label{sec:excp}

This can be thought of as an example of nonlocal branching. To implement a try/catch block, a stack of error (failure) continuations has to be implemented alongside the ordinary (success) continuation. Matt Might shows this in his blog post about continuations.

Alternatively, rather than only passing the ordinary continuation to each function in CPS, both the success and failure continuations may be passed as parameters to every function. This may be a little bit more inefficient but has the same effect. This is how failure continuations were passed around in the nondeterministic interpreter.

\subsubsection{Coroutines (and generators)}
\label{sec:coro}

As mentioned earlier, continuations are functionally very similar to (and potentially more powerful than) threads. Thus, continuations may be used to implement cooperatively-scheduled threads\footnote{Threads are typically \textit{preemptively scheduled}, which means that they yield control to another thread at arbitrary moments in their execution (generally to maintain performance or responsiveness). \textit{Non-preemptive} or \textit{cooperative} scheduling means that a thread only yields to another thread explicitly.}, coroutines (equivalent to cooperative threads), and generators (a subset of coroutines).

\begin{description}
  
\item[Cooperative threading system] Continuations can be used to implement a cooperatively-scheduled threading system by maintaining a collection of continuations representing threads. Each thread may voluntarily yield to another available thread via the yield instruction. The collection may be a queue and the next continuation in the queue will be chosen when a thread yields; this forms a very simple round-robin scheduling algorithm. Matt Might's blog post on continuations includes this as an example. This allows us to create concurrency (but not parallelism) in our interpreter.

  Kotlin has an implementation of cooperative threading that is called coroutines (which are equivalent -- see next example).
  
\item[Coroutines] A coroutine is a generalization of a subroutine (procedure) that maintains execution state between calls. It may exit either normally (by returning) or by \textit{yield}ing to another coroutine; when it is invoked again, it will resume execution from the yield point. Coroutines are functionally equivalent to cooperatively-scheduled threads.

  A simple way to implement coroutines is to store a table of continuations for each function. Yielding to a coroutine would mean looking up its continuation and invoking it with the yielded value.
  
\item[Generators] Generators are a restricted type of coroutine that is very useful. A generator is a function that yields values one at a time. They are useful as iterators over arbitrary data structures. To the outsider, calling the function successively produces successive values of the collection; this works because the function saves its execution context between calls and thus doesn't lose its position when iterating over the data structure.

  Generators offer a nice solution to iteration that are roughly equivalent to streams (streams are employed in \textit{SICP} section 4.4 as an iterator, but a generator would have worked as well). If neither streams nor generators were present, then implementing an iterator function without nonlocal state becomes difficult.

  Generators are a strict subset of coroutines because the generator function can only yield to its caller, while a full coroutine can yield to any other coroutine. This simplifies the implementation and does not require a table of continuations. Rather, the two functions (generator and consumer) simply pass back and forth the new continuations and the yielded values.

  Many languages implement generators due to their ubiquity, even if they do not implement coroutines.
\end{description}

\subsection{Interesting properties of continuations}
\label{sec:inte}

\subsubsection{One procedure call, multiple returns}
\label{sec:mult}

TODO: include Matt Might's idiom here
TODO: discard current continuation if a continuation is called

\subsubsection{Continuations with unlimited extent}
\label{sec:unli}

TODO: move this into the implemenation section?
TODO: talk about TCO?

\subsubsection{Implementation with threads (or vice versa)}
\label{sec:thre}

\subsubsection{Flavors of continuations}
\label{sec:flav}

TODO: talk about escape continuations and delimited continuations

\subsection{Analogs in other languages}
\label{sec:anal}

TODO: Haskell Cont monad

TODO: C setjmp/longjmp: TODO give example

TODO: Python/Kotlin/Go coroutines

TODO: talk about CSP % https://bytes.yingw787.com/posts/2019/02/09/concurrency_with_python_csp_and_coroutines/

\section{Multiple continuations}
\label{sec:mulc}



\section{Implementation}
\label{sec:impl}

\section{Conclusion}
\label{sec:conc}

\section{References}
\label{sec:refe}



\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
